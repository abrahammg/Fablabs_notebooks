{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN to Generate Handwritten Digits (MNIST)\n",
    "\n",
    "In this notebook, we will build and train a Generative Adversarial Network (GAN) to create convincing images of handwritten digits.\n",
    "\n",
    "## How does a GAN work?\n",
    "\n",
    "A GAN consists of two neural networks that compete against each other:\n",
    "\n",
    "1.  **The Generator**: Tries to create fake images that are as realistic as possible. It starts from random noise and learns to transform it into something that resembles the real data.\n",
    "2.  **The Discriminator**: Acts as a judge. Its job is to look at an image and decide if it is real (from the training dataset) or fake (created by the generator).\n",
    "\n",
    "The training is a zero-sum game:\n",
    "- The **discriminator** improves by getting better at detecting fakes.\n",
    "- The **generator** improves by getting better at \"fooling\" the discriminator.\n",
    "\n",
    "Over time, the generator becomes so good that its images are almost indistinguishable from real ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup\n",
    "\n",
    "In the following cell, we will import all the necessary libraries for our project. This is the first step in any Python script, where we gather the tools we need to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Preparation\n",
    "\n",
    "The next cell handles loading and preparing our data. We will:\n",
    "1.  Load the standard MNIST dataset of handwritten digits directly from TensorFlow.\n",
    "2.  Display the first 100 images to visually inspect our data.\n",
    "3.  Reshape and normalize the images to a format suitable for the neural network.\n",
    "4.  Create an efficient TensorFlow `Dataset` object to feed the data to our model in batches during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset. It returns training and testing sets. We only need the training images.\n",
    "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "print(\"\\nShowing the first 100 example images:\")\n",
    "\n",
    "# Create a figure to display the images, with a size of 5x5 inches.\n",
    "plt.figure(figsize=(5, 5))\n",
    "\n",
    "# Loop 100 times to show the first 100 images.\n",
    "for i in range(100):\n",
    "    # Create a subplot in a 10x10 grid at position i+1.\n",
    "    plt.subplot(10, 10, i + 1)\n",
    "    \n",
    "    # Display the i-th image in grayscale.\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    \n",
    "    # Remove the numbered ticks from the x and y axes for a cleaner look.\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "# Show the final figure with all the subplots.\n",
    "plt.show()\n",
    "\n",
    "# Reshape the images from (60000, 28, 28) to (60000, 28, 28, 1) because convolutional\n",
    "# layers expect a channel dimension. We also convert the pixel values to float32 type.\n",
    "train_images_processed = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "\n",
    "# Normalize the pixel values from the range [0, 255] to [-1, 1]. This helps stabilize training.\n",
    "train_images_processed = (train_images_processed - 127.5) / 127.5\n",
    "\n",
    "# Define constants for creating the dataset.\n",
    "BUFFER_SIZE = 60000 # Number of items to shuffle.\n",
    "BATCH_SIZE = 256    # Number of images per training batch.\n",
    "\n",
    "# 1. Define the generator function.\n",
    "# This function simply yields the images one by one. Shuffling will be handled by tf.data.\n",
    "def data_generator():\n",
    "    for img in train_images_processed:\n",
    "        yield img\n",
    "\n",
    "# 2. Create the Dataset using from_generator.\n",
    "# This method is much more memory-efficient.\n",
    "# We tell TensorFlow what data type and shape to expect (the \"output_signature\").\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    data_generator,\n",
    "    output_signature=tf.TensorSpec(shape=(28, 28, 1), dtype=tf.float32)\n",
    ")\n",
    "\n",
    "# 3. Apply shuffle and batch operations to the new dataset.\n",
    "# This is the recommended way to handle shuffling and batching with large datasets.\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "print(\"\\nDataset ready for training (created efficiently with a generator).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Creating the Generator Model\n",
    "\n",
    "The generator's job is to take a random noise vector and transform it into a 28x28 image. It's essentially a reverse convolutional network.\n",
    "\n",
    "- `def make_generator_model():`: We define a function to build our model.\n",
    "- `model.add(layers.Input(shape=(100,)))`: It starts with an input layer that accepts a 100-dimension noise vector.\n",
    "- `model.add(layers.Dense(...))`: A fully connected layer expands this vector into a larger block of data.\n",
    "- `model.add(layers.Reshape(...))`: This reshapes the data into a small 7x7 'image' with many channels (256).\n",
    "- `model.add(layers.Conv2DTranspose(...))`: These are deconvolutional layers. They perform upsampling, taking the small 7x7 feature maps and intelligently scaling them up, first to 14x14, and then to the final 28x28 size.\n",
    "- `activation=\"tanh\"`: The final layer uses a `tanh` activation to ensure the output pixel values are between -1 and 1, matching our normalized real images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Input(shape=(100,)))\n",
    "    \n",
    "    model.add(layers.Dense(7 * 7 * 256, use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1),\n",
    "                                     padding=\"same\", use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2),\n",
    "                                     padding=\"same\", use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2),padding=\"same\", use_bias=False,activation=\"tanh\"))\n",
    "\n",
    "    return model\n",
    "    \n",
    "generator = make_generator_model()\n",
    "\n",
    "print(\"Generator model created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating the Discriminator Model\n",
    "\n",
    "The discriminator is a standard Convolutional Neural Network (CNN) for image classification. Its goal is to take an image and output a single value indicating whether it thinks the image is real or fake.\n",
    "\n",
    "- `def make_discriminator_model():`: Defines the function to build the discriminator.\n",
    "- `model.add(layers.Conv2D(...))`: These are convolutional layers that process the input image, extracting features and downsampling it (making it smaller) with `strides=(2, 2)`.\n",
    "- `model.add(layers.LeakyReLU())`: The Leaky ReLU activation function helps the network learn.\n",
    "- `model.add(layers.Dropout(0.3))`: This layer randomly deactivates 30% of its input units during training to prevent the model from becoming too specialized to the training data (overfitting).\n",
    "- `model.add(layers.Flatten())`: This layer converts the 2D feature maps from the convolutional layers into a single 1D vector.\n",
    "- `model.add(layers.Dense(1))`: The final output layer has one neuron, which will produce a single logit value indicating the model's prediction (real or fake)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model\n",
    "\n",
    "discriminator = make_discriminator_model()\n",
    "\n",
    "print(\"Discriminator model created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Defining Losses and Optimizers\n",
    "\n",
    "Here we define the functions that will measure how 'wrong' our models are (the loss) and the algorithms that will update them (the optimizers).\n",
    "\n",
    "- `cross_entropy`: We create an instance of `BinaryCrossentropy`, which is the correct loss function for a binary (real/fake) classification problem.\n",
    "- `discriminator_loss`: This function calculates the discriminator's loss. It's the sum of two parts: how well it identifies real images as real (`real_loss`) and how well it identifies fake images as fake (`fake_loss`).\n",
    "- `generator_loss`: This function calculates the generator's loss. It measures how well the discriminator was fooled. The generator wins (has low loss) if the discriminator classifies its fake images as real (i.e., close to 1).\n",
    "- `..._optimizer`: We create an `Adam` optimizer for each network. This algorithm will be used to apply the calculated gradients and update the networks' weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "generator_optimizer = optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Setting up the Training Loop\n",
    "\n",
    "This cell defines the logic for a single step of training and a helper function to visualize progress.\n",
    "\n",
    "- `EPOCHS`, `noise_dim`, etc.: We define some constants for the training process.\n",
    "- `seed`: We create a fixed batch of random noise. This will be fed to the generator at the end of each epoch to create sample images, allowing us to visually track its improvement over time.\n",
    "- `@tf.function`: This is a decorator that converts the Python function into a high-performance TensorFlow graph, which makes training much faster.\n",
    "- `def train_step(images)`: This function encapsulates one full training step for a single batch of data.\n",
    "    - `with tf.GradientTape() as ...`: The `GradientTape` is a crucial tool that 'records' all operations. This allows TensorFlow to automatically calculate the gradients needed for backpropagation.\n",
    "    - The code inside the `with` block generates fake images, gets the discriminator's predictions for both real and fake images, and calculates the losses for both networks.\n",
    "    - `gradients_of_... = ...gradient(...)`: The tape computes the gradients of the loss with respect to each network's trainable weights.\n",
    "    - `...optimizer.apply_gradients(...)`: The optimizer uses these calculated gradients to update the weights of the generator and discriminator.\n",
    "- `if not os.path.exists(...)`: This checks if a directory named `gan_images` exists to save our output images.\n",
    "- `os.makedirs(...)`: If the directory does not exist, it is created.\n",
    "- `def generate_and_save_images(...)`: A helper function that uses the generator to create images from the fixed `seed` noise, then uses `matplotlib` to create a grid of these images and save it to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50 # You can start with fewer (e.g., 50) for faster training\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])\n",
    "\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "if not os.path.exists('gan_images'):\n",
    "    os.makedirs('gan_images')\n",
    "\n",
    "def generate_and_save_images(model, epoch, test_input):\n",
    "    predictions = model(test_input, training=False)\n",
    "    \n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.savefig('gan_images/image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training the GAN\n",
    "\n",
    "This is where we put everything together and start the training. The code defines a `train` function that will manage the entire process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for display clearing and time tracking.\n",
    "from IPython import display\n",
    "import time\n",
    "\n",
    "# Define the main training function.\n",
    "def train(dataset, epochs):\n",
    "    # Loop for the specified number of epochs.\n",
    "    for epoch in range(epochs):\n",
    "        # Record the start time.\n",
    "        start = time.time()\n",
    "\n",
    "        # Loop through each batch in the dataset.\n",
    "        for image_batch in dataset:\n",
    "            # Perform a single training step on the batch.\n",
    "            train_step(image_batch)\n",
    "\n",
    "        # Clear the output of the cell to show the new generated images.\n",
    "        display.clear_output(wait=True)\n",
    "        # Generate and save sample images to visualize progress.\n",
    "        generate_and_save_images(generator,\n",
    "                                 epoch + 1,\n",
    "                                 seed)\n",
    "\n",
    "        # Print the time taken for the epoch to complete.\n",
    "        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "    # After the final epoch, clear the output and show the final set of generated images.\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator, epochs, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing the Training\n",
    "\n",
    "The final cell calls the `train` function, passing our prepared dataset and the number of epochs. This command will start the actual training process, which may take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Trainning model ...\")\n",
    "\n",
    "train(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "\n",
    "Congratulations! You have trained a GAN from scratch.\n",
    "\n",
    "You can look in the `gan_images` folder to see the generator's evolution. At the beginning, the images will be pure noise, but as the epochs go by, they should start to take the shape of recognizable digits.\n",
    "\n",
    "### Possible next steps:\n",
    "- **Train longer**: GANs benefit from more training epochs.\n",
    "- **Adjust hyperparameters**: Try different learning rates, batch sizes, or network architectures.\n",
    "- **Try with other datasets**: You can adapt this GAN to train on other datasets, such as [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) or [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
