{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d61a34cd",
   "metadata": {},
   "source": [
    "# Module 3: Creating a Simple CNN\n",
    "\n",
    "## Practice: Training a Convolutional Neural Network on CIFAR-10\n",
    "\n",
    "In this notebook, we will train a simple Convolutional Neural Network (CNN) on the CIFAR-10 dataset. CIFAR-10 consists of 60,000 32x32 color images across 10 classes (airplane, car, bird, cat, etc.).\n",
    "\n",
    "Imagine an IoT device (e.g., Raspberry Pi + camera) capturing images and classifying them either on the device (edge computing) or in the cloud. This example demonstrates how a CNN learns to recognize objects in images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a48abe",
   "metadata": {},
   "source": [
    "## 1. Imports and Dataset Loading\n",
    "\n",
    "We start by importing necessary libraries and loading the CIFAR-10 dataset directly from Keras. We'll also normalize pixel values to the [0,1] range.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01160479",
   "metadata": {},
   "source": [
    "In this cell we import the necessary libraries and load the CIFAR-10 dataset:\n",
    "\n",
    "- **tensorflow**: For building and training deep learning models.\n",
    "- **datasets, layers, models** from Keras: To handle data and define architectures.\n",
    "- **matplotlib.pyplot** and **numpy**: For plotting and numerical operations.\n",
    "\n",
    "We load CIFAR-10 (60,000 32×32 color images in 10 classes), normalize pixel values by dividing by 255, and print the shapes of the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77823143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from keras.layers import Input\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "print(\"Libraries imported succesfully\")\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
    "\n",
    "print(\"Dataset loaded successfully\")\n",
    "\n",
    "# Normalize pixel values\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test  = x_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3523bd4",
   "metadata": {},
   "source": [
    "## 2. Visualizing the Data\n",
    "\n",
    "Let's look at a few samples from the training set to understand what the images look like. We'll display the first 5 images with their labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdbd3cc",
   "metadata": {},
   "source": [
    "In this cell we define class names and display the first 5 training images:\n",
    "\n",
    "- Create a `class_names` list with human-readable labels for each class.\n",
    "- Use `plt.subplots` to create a row of 5 subplots.\n",
    "- For each image, display it, set the title to its label, and hide the axes.\n",
    "\n",
    "This helps inspect example data and understand class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660a810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\n",
    "               \"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]\n",
    "\n",
    "# Show first 5 images\n",
    "fig, axes = plt.subplots(1, 5, figsize=(5, 2))\n",
    "for i in range(5):\n",
    "    axes[i].imshow(x_train[i])\n",
    "    label = y_train[i][0]  # because y_train[i] is an array\n",
    "    axes[i].set_title(class_names[label])\n",
    "    axes[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386e2e0d",
   "metadata": {},
   "source": [
    "## 3. Building the CNN Model\n",
    "\n",
    "We will construct a simple CNN with two convolutional blocks followed by pooling layers, then flatten the output and add fully connected layers for classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da158780",
   "metadata": {},
   "source": [
    "In this cell we define a simple Convolutional Neural Network (CNN) architecture:\n",
    "\n",
    "- Start with a Keras **Sequential** model.  \n",
    "- Use an explicit **Input** layer to specify the input shape (32×32×3).  \n",
    "- First convolutional block: `Conv2D` with 32 filters of size 3×3 and **ReLU** activation, followed by `MaxPooling2D` (2×2).  \n",
    "- Second convolutional block: `Conv2D` with 64 filters of size 3×3 and **ReLU** activation, followed by `MaxPooling2D` (2×2).  \n",
    "- Flatten the feature maps with `Flatten`.  \n",
    "- Fully connected layers: a `Dense` layer with 64 neurons and **ReLU**, and a final `Dense` layer with 10 neurons and **softmax** for 10-class classification.  \n",
    "- Finally, display the model summary with `model.summary()`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3120c4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    Input(shape=(32, 32, 3)),\n",
    "\n",
    "    # Primeiro bloque convolucional\n",
    "    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    # Segundo bloque convolucional\n",
    "    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    # Aplanar os mapas de características\n",
    "    layers.Flatten(),\n",
    "\n",
    "    # Capas densas para clasificación\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "print(\"Model created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63872cd9",
   "metadata": {},
   "source": [
    "## 4. Compiling and Training the Model\n",
    "\n",
    "We'll compile the model using the Adam optimizer and sparse categorical crossentropy loss, then train for 5 epochs with a batch size of 64.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c309195",
   "metadata": {},
   "source": [
    "In this cell we compile and train the defined model:\n",
    "\n",
    "- **Optimizer:** Adam.\n",
    "- **Loss Function:** sparse_categorical_crossentropy (suitable for integer labels).\n",
    "- **Metric:** accuracy.\n",
    "- **Fit Parameters:** 5 epochs, batch size 64, using the test set for validation.\n",
    "\n",
    "The returned `history` object records loss and accuracy over training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd36f985",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=5, \n",
    "                    validation_data=(x_test, y_test), \n",
    "                    batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6aa45d",
   "metadata": {},
   "source": [
    "## 5. Evaluating the Model\n",
    "\n",
    "Evaluate the trained CNN on the test set to measure its accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5a8cba",
   "metadata": {},
   "source": [
    "In this cell we evaluate the model on the test dataset:\n",
    "\n",
    "- Call `model.evaluate` with `x_test` and `y_test`.\n",
    "- Retrieve `test_loss` and `test_acc`.\n",
    "- Print the final test accuracy to quantify model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bceeb980",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"Test accuracy: {test_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06fad1e",
   "metadata": {},
   "source": [
    "## 6. Classifying an External Image via URL\n",
    "\n",
    "To demonstrate how our trained CNN can classify new, real-world images, we can load an image from any URL:\n",
    "\n",
    "1. We prompt the user to enter an image URL.\n",
    "2. We download the image using `requests` and open it with `PIL.Image`.\n",
    "3. We convert it to RGB, resize it to the required input shape (32×32), and normalize pixel values to `[0.0, 1.0]`.\n",
    "4. We expand dimensions to create a batch of size 1, which is needed for `model.predict`.\n",
    "5. We run the model to obtain prediction probabilities.\n",
    "6. We select the class with the highest probability and display both the class name and the probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2624c406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt for the image URL\n",
    "url = input(\"Image URL: \")\n",
    "\n",
    "# Download and open the image\n",
    "response = requests.get(url)\n",
    "img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "\n",
    "# Resize to 32×32 and normalize pixel values to [0,1]\n",
    "img = img.resize((32, 32))\n",
    "img_array = np.array(img).astype('float32') / 255.0\n",
    "\n",
    "# Create a batch of size 1\n",
    "img_batch = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "# Make a prediction\n",
    "preds = model.predict(img_batch)\n",
    "class_idx = np.argmax(preds, axis=1)[0]\n",
    "prob = preds[0][class_idx]\n",
    "\n",
    "# Display the result\n",
    "print(f\"Predicted class: {class_names[class_idx]}  —  Probability: {prob:.2%}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
