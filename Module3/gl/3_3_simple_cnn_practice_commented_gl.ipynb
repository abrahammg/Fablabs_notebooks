{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d61a34cd",
   "metadata": {},
   "source": [
    "# Module 3: Creating a Simple CNN\n",
    "\n",
    "## Practice: Training a Convolutional Neural Network on CIFAR-10\n",
    "\n",
    "In this notebook, we will train a simple Convolutional Neural Network (CNN) on the CIFAR-10 dataset. CIFAR-10 consists of 60,000 32x32 color images across 10 classes (airplane, car, bird, cat, etc.).\n",
    "\n",
    "Imagine an IoT device (e.g., Raspberry Pi + camera) capturing images and classifying them either on the device (edge computing) or in the cloud. This example demonstrates how a CNN learns to recognize objects in images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a48abe",
   "metadata": {},
   "source": [
    "## 1. Imports and Dataset Loading\n",
    "\n",
    "We start by importing necessary libraries and loading the CIFAR-10 dataset directly from Keras. We'll also normalize pixel values to the [0,1] range.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0761fbe",
   "metadata": {},
   "source": [
    "Nesta celda importamos as librarías necesarias e cargamos o conxunto de datos CIFAR-10:\n",
    "\n",
    "- **tensorflow**: Para construír e adestrar modelos de deep learning.\n",
    "- **datasets, layers, models** de Keras: Para manexar datos e definir arquitecturas.\n",
    "- **matplotlib.pyplot** e **numpy**: Para visualización e manipulación numérica.\n",
    "\n",
    "Cargamos o CIFAR-10, que contén 60.000 imaxes de 32×32 en 10 clases, e normalizamos os píxeles dividindo entre 255. Finalmente, imprimimos as formas dos conxuntos de adestramento e proba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad97f67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test  = x_test.astype('float32') / 255.0\n",
    "\n",
    "print(\"Training data shape:\", x_train.shape)\n",
    "print(\"Testing data shape:\", x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3523bd4",
   "metadata": {},
   "source": [
    "## 2. Visualizing the Data\n",
    "\n",
    "Let's look at a few samples from the training set to understand what the images look like. We'll display the first 5 images with their labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64f8096",
   "metadata": {},
   "source": [
    "Nesta celda definimos os nomes das clases e mostramos as primeiras 5 imaxes de adestramento:\n",
    "\n",
    "- Creamos unha lista `class_names` con etiquetas lexibles para cada clase.\n",
    "- Usamos `plt.subplots` para crear unha fila de 5 subplots.\n",
    "- Para cada imaxe, mostramos a imaxe, poñemos o título coa clase correspondente e ocultamos os eixes.\n",
    "\n",
    "Isto serve para inspeccionar exemplos do conxunto de datos e entender a dispoñibilidade das clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f21161a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\n",
    "               \"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]\n",
    "\n",
    "# Show first 5 images\n",
    "fig, axes = plt.subplots(1, 5, figsize=(10, 2))\n",
    "for i in range(5):\n",
    "    axes[i].imshow(x_train[i])\n",
    "    label = y_train[i][0]  # because y_train[i] is an array\n",
    "    axes[i].set_title(class_names[label])\n",
    "    axes[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386e2e0d",
   "metadata": {},
   "source": [
    "## 3. Building the CNN Model\n",
    "\n",
    "We will construct a simple CNN with two convolutional blocks followed by pooling layers, then flatten the output and add fully connected layers for classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e24bf6f",
   "metadata": {},
   "source": [
    "Nesta celda definimos a arquitectura dunha Rede Convolucional (CNN) simple:\n",
    "\n",
    "- Comezamos cun modelo **Sequential** de Keras.  \n",
    "- Usamos unha capa **Input** explícita para indicar a forma dos datos de entrada (32×32×3).  \n",
    "- Primeiro bloque convolucional: `Conv2D` con 32 filtros de tamaño 3×3 e activación **ReLU**, seguido de `MaxPooling2D` 2×2.  \n",
    "- Segundo bloque convolucional: `Conv2D` con 64 filtros 3×3 e activación **ReLU**, seguido de `MaxPooling2D` 2×2.  \n",
    "- Achatamos as características con `Flatten`.  \n",
    "- Capas totalmente conectadas: unha `Dense` de 64 neuronas con **ReLU**, e a capa final `Dense` de 10 neuronas con **softmax** para clasificación en 10 clases.  \n",
    "- Rematamos mostrando un resumo do modelo con `model.summary()`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e5ee59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "# Specify the input shape explicitly as the first layer\n",
    "model.add(Input(shape=(32, 32, 3)))\n",
    "\n",
    "# First convolutional block\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Second convolutional block\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten the feature maps\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Fully connected layers\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))  # 10 classes\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63872cd9",
   "metadata": {},
   "source": [
    "## 4. Compiling and Training the Model\n",
    "\n",
    "We'll compile the model using the Adam optimizer and sparse categorical crossentropy loss, then train for 5 epochs with a batch size of 64.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b1a9b1",
   "metadata": {},
   "source": [
    "Nesta celda compilamos e adestramos o modelo definido anteriormente:\n",
    "\n",
    "- **Optimizer:** Adam.\n",
    "- **Loss Function:** sparse_categorical_crossentropy (axeitado para etiquetas enteiras).\n",
    "- **Metrics:** accuracy.\n",
    "- **Fit:** 5 épocas, tamaño de batch 64, usando test set para validación.\n",
    "\n",
    "O obxecto `history` almacena a evolución da perda e precisión durante o adestramento e validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d82787",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=5, \n",
    "                    validation_data=(x_test, y_test), \n",
    "                    batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6aa45d",
   "metadata": {},
   "source": [
    "## 5. Evaluating the Model\n",
    "\n",
    "Evaluate the trained CNN on the test set to measure its accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c498a08e",
   "metadata": {},
   "source": [
    "Nesta celda avaliamos o modelo nos datos de proba:\n",
    "\n",
    "- Chamamos `model.evaluate` con `x_test` e `y_test`.\n",
    "- Obtemos `test_loss` e `test_acc`.\n",
    "- Imprimimos a precisión final no conxunto de proba para cuantificar o rendemento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886f563f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f\"Test accuracy: {test_acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b889e5",
   "metadata": {},
   "source": [
    "## 6. Making Predictions\n",
    "\n",
    "Let's make predictions on a few test images and compare the predicted labels to the true labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4c1e5d",
   "metadata": {},
   "source": [
    "Nesta celda realizamos predicións sobre as primeiras 5 imaxes de test:\n",
    "\n",
    "- Usamos `model.predict` para obter as probabilidades de cada clase.\n",
    "- Determinamos as etiquetas predicidas con `np.argmax`.\n",
    "- Deseñamos unha figura con 5 imaxes e mostramos cada unha coa súa predición."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d689a8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt for the image URL\n",
    "url = input(\"Image URL: \")\n",
    "\n",
    "# Download and open the image\n",
    "response = requests.get(url)\n",
    "img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "\n",
    "# Resize to 32×32 and normalize pixel values to [0,1]\n",
    "img = img.resize((32, 32))\n",
    "img_array = np.array(img).astype('float32') / 255.0\n",
    "\n",
    "# Create a batch of size 1\n",
    "img_batch = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "# Make a prediction\n",
    "preds = model.predict(img_batch)\n",
    "class_idx = np.argmax(preds, axis=1)[0]\n",
    "prob = preds[0][class_idx]\n",
    "\n",
    "# Display the result\n",
    "print(f\"Predicted class: {class_names[class_idx]}  —  Probability: {prob:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd5035e",
   "metadata": {},
   "source": [
    "Nesta celda presentamos un exemplo de modelo estendido con regularización e plot da historia de adestramento:\n",
    "\n",
    "- Definimos `model2` con bloques Conv2D, MaxPooling e un **Dropout** ao 25% para evitar sobreaxuste.\n",
    "- Capa final Dense de 10 neuronas con softmax.\n",
    "- Asumimos que almacenamos o obxecto `history2` tras adestrar o modelo extendido.\n",
    "- Usamos `plt` para trazar dúas gráficas: precisión e perda de adestramento e validación ao longo das épocas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
