{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c8b2a3f",
   "metadata": {},
   "source": [
    "# Module 3: Generative Adversarial Network (GAN) Practice\n",
    "\n",
    "## Practice: Generating Handwritten Digits with GANs\n",
    "\n",
    "In this notebook, we will train a Generative Adversarial Network (GAN) to generate images of handwritten digits similar to those in the MNIST dataset.\n",
    "\n",
    "GANs are powerful for generating new content based on real data. The **Generator** network creates digit images that look real, while the **Discriminator** network tries to distinguish between real and fake digits. Over time, the Generator improves until it can fool the Discriminator.\n",
    "\n",
    "This technique is widely used for deepfake creation, digital art, and image enhancement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a6bcd6",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries & Load MNIST Dataset\n",
    "\n",
    "We import TensorFlow/Keras for building models, NumPy for numerical operations, and Matplotlib for visualization.  \n",
    "We load the MNIST dataset from Keras, normalize pixel values to [-1, 1], and reshape the data for our models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7239c0b3",
   "metadata": {},
   "source": [
    "Nesta celda importamos as librarías necesarias:\n",
    "\n",
    "- **tensorflow** e **keras**: Para definir modelos e capas.\n",
    "- **numpy**: Para xerar ruído e manipular arrays.\n",
    "- **matplotlib.pyplot**: Para visualizar as imaxes.\n",
    "\n",
    "A continuación cargaremos o dataset MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9590e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and prepare the MNIST dataset\n",
    "(train_images, _), (_, _) = keras.datasets.mnist.load_data()\n",
    "train_images = (train_images.astype('float32') - 127.5) / 127.5  # Normalize to [-1,1]\n",
    "train_images = np.expand_dims(train_images, axis=-1)  # Add channel dimension\n",
    "\n",
    "print(\"Train images shape:\", train_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dd2c3b",
   "metadata": {},
   "source": [
    "## 2. Build the Generator\n",
    "\n",
    "The Generator network takes a random noise vector (`latent_dim`) as input and outputs a 28×28 grayscale image using dense layers and reshaping.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12433bb",
   "metadata": {},
   "source": [
    "Nesta celda cargamos e preprocesamos o dataset MNIST:\n",
    "\n",
    "1. Usamos `keras.datasets.mnist.load_data()` para obter imaxes de díxitos.\n",
    "2. Normalizamos os píxeles ao rango [-1,1] para axustalos ao rango da saída tanh.\n",
    "3. Remodelamos os datos para ter forma (n_batches, 28, 28, 1).\n",
    "\n",
    "Xeramos tamén un lote de ruído para alimentar o xerador no adestramento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c54725",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "\n",
    "def build_generator():\n",
    "    model = keras.Sequential([\n",
    "        keras.Input(shape=(latent_dim,)),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(28 * 28 * 1, activation='tanh'),\n",
    "        layers.Reshape((28, 28, 1))\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "generator = build_generator()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed6fb43",
   "metadata": {},
   "source": [
    "## 3. Build the Discriminator\n",
    "\n",
    "The Discriminator network takes a 28×28 image as input, flattens it, and uses dense layers to output a probability that the image is real.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b0c4d6",
   "metadata": {},
   "source": [
    "Nesta celda definimos o xerador:\n",
    "\n",
    "- Creamos un modelo **Sequential**.\n",
    "- Engadimos unha capa **Dense** para transformar o ruído nun vector de tamaño 7×7×128.\n",
    "- Aplicamos **LeakyReLU** e **BatchNormalization** para estabilizar o adestramento.\n",
    "- Remodelamos o vector nun tensor 7×7×128.\n",
    "- Empregamos dúas capas **Conv2DTranspose** sucesivas para chegar a 28×28×1.\n",
    "- A capa final usa **activation='tanh'** para producir píxeles en [-1,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915b41ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    model = keras.Sequential([\n",
    "        keras.Input(shape=(28, 28, 1)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=keras.optimizers.Adam(0.0002), loss='binary_crossentropy')\n",
    "    return model\n",
    "\n",
    "discriminator = build_discriminator()\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83c7888",
   "metadata": {},
   "source": [
    "## 4. Configure the GAN\n",
    "\n",
    "We freeze the Discriminator when training the Generator, then compile the combined GAN model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04533008",
   "metadata": {},
   "source": [
    "Nesta celda definimos o discriminador:\n",
    "\n",
    "- Creamos un modelo **Sequential**.\n",
    "- Engadimos varias capas **Conv2D** con activación **LeakyReLU** e **Dropout**.\n",
    "- Estas capas extraen características das imaxes de 28×28×1.\n",
    "- Achátanse as características co **Flatten**.\n",
    "- Remátase cunha capa **Dense(1)** con **sigmoid** para indicar real/falso.\n",
    "- Compilamos o discriminador con optimizador **Adam** e perda **binary_crossentropy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b466601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Generator and Discriminator\n",
    "discriminator.trainable = False\n",
    "\n",
    "gan_input = keras.Input(shape=(latent_dim,))\n",
    "gan_output = discriminator(generator(gan_input))\n",
    "gan = keras.Model(gan_input, gan_output)\n",
    "\n",
    "gan.compile(optimizer=keras.optimizers.Adam(0.0002), loss='binary_crossentropy')\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7964f7a5",
   "metadata": {},
   "source": [
    "## 5. Train the GAN\n",
    "\n",
    "We train for a number of epochs. In each step:\n",
    "1. Sample real images and label them as real (1).\n",
    "2. Generate fake images and label them as fake (0).\n",
    "3. Train Discriminator on both real and fake.\n",
    "4. Train Generator via the GAN model with misleading labels (1) to fool the Discriminator.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a19714",
   "metadata": {},
   "source": [
    "Nesta celda implementamos a función de adestramento:\n",
    "\n",
    "- Percorremos épocas e lotes de datos reais.\n",
    "- Xeramos un lote de ruído e producimos imaxes falsas co xerador.\n",
    "- Combinamos imaxes reais e falsas e etiquetas.\n",
    "- Actualizamos primeiro o discriminador coas súas perdas, logo o xerador coas súas.\n",
    "- Cada certas épocas, gardamos e mostramos mostras xeradas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f01405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "epochs = 3000\n",
    "batch_size = 128\n",
    "buffer_size = train_images.shape[0]\n",
    "\n",
    "# Create dataset pipeline\n",
    "dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(buffer_size).batch(batch_size)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    for real_images in dataset:\n",
    "        # Train Discriminator\n",
    "        noise = tf.random.normal([batch_size, latent_dim])\n",
    "        fake_images = generator(noise, training=True)\n",
    "        \n",
    "        real_labels = tf.ones((batch_size, 1))\n",
    "        fake_labels = tf.zeros((batch_size, 1))\n",
    "        \n",
    "        d_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
    "        d_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)\n",
    "        d_loss = 0.5 * (d_loss_real + d_loss_fake)\n",
    "        \n",
    "        # Train Generator\n",
    "        noise = tf.random.normal([batch_size, latent_dim])\n",
    "        misleading_labels = tf.ones((batch_size, 1))\n",
    "        g_loss = gan.train_on_batch(noise, misleading_labels)\n",
    "    \n",
    "    # Log progress\n",
    "    if epoch % 500 == 0:\n",
    "        print(f'Epoch {epoch}, D Loss: {d_loss:.4f}, G Loss: {g_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f65b02",
   "metadata": {},
   "source": [
    "## 6. Generate AI-Created Digits\n",
    "\n",
    "After training, we generate new digit images by sampling random noise vectors and using the Generator.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6400751d",
   "metadata": {},
   "source": [
    "Nesta celda executamos o adestramento do GAN:\n",
    "\n",
    "- Chamamos á función `train` indicando número de épocas e tamaño de lote.\n",
    "- Ao rematar, visualizamos as imaxes xeradas finais.\n",
    "\n",
    "Observaremos como, ao longo do adestramento, os díxitos van acadando maior nitidez e realismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354d1d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and plot digits\n",
    "noise = tf.random.normal([5, latent_dim])\n",
    "generated_images = generator.predict(noise)\n",
    "\n",
    "plt.figure(figsize=(10, 2))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.imshow(generated_images[i, :, :, 0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
