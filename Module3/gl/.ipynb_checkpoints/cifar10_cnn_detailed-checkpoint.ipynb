{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea8aa2fd",
   "metadata": {},
   "source": [
    "# Image Classification with a CNN on CIFAR-10\n",
    "\n",
    "In this notebook, we will build, train, and evaluate a Convolutional Neural Network (CNN) to classify images from the CIFAR-10 dataset. We will provide detailed explanations for each step, including the purpose of each parameter and layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a727630",
   "metadata": {},
   "source": [
    "## 1. Imports and Dataset Loading\n",
    "\n",
    "First, we import the necessary libraries:\n",
    "\n",
    "- `tensorflow`: The main library for building and training neural networks.\n",
    "- `datasets, layers, models`: Submodules from `tensorflow.keras` to load data and define our model layers.\n",
    "- `matplotlib.pyplot`: To visualize sample images.\n",
    "- `numpy`: For numerical operations and array handling.\n",
    "\n",
    "Then, we load the CIFAR-10 dataset directly from Keras and normalize pixel values to the range [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e1f241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values from integers [0, 255] to floats [0.0, 1.0]\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "print('Training data shape:', x_train.shape)\n",
    "print('Testing data shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcd3a3d",
   "metadata": {},
   "source": [
    "## 2. Visualizing the Data\n",
    "\n",
    "Before training, it's helpful to see what the images look like. We have 10 classes:\n",
    "`airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck`.\n",
    "We will plot the first 5 images from the training set:\n",
    "\n",
    "- `figsize=(10, 2)`: width and height of the figure in inches.\n",
    "- `axes[i].imshow(...)`: Display the image at index `i`.\n",
    "- `axes[i].set_title(...)`: Show the corresponding class name.\n",
    "- `axes[i].axis('off')`: Hide axis ticks for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fb5e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane','automobile','bird','cat','deer',\n",
    "               'dog','frog','horse','ship','truck']\n",
    "\n",
    "# Plot first 5 images\n",
    "fig, axes = plt.subplots(1, 5, figsize=(10, 2))\n",
    "for i in range(5):\n",
    "    axes[i].imshow(x_train[i])\n",
    "    label = y_train[i][0]  # y_train[i] is an array like [label]\n",
    "    axes[i].set_title(class_names[label])\n",
    "    axes[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c01126",
   "metadata": {},
   "source": [
    "## 3. Building the CNN Model\n",
    "\n",
    "We will define a Sequential CNN model consisting of:\n",
    "\n",
    "1. **Conv2D layer** with:\n",
    "   - `filters=32`: Number of convolutional kernels (feature detectors).\n",
    "   - `kernel_size=(3, 3)`: Size of each kernel window.\n",
    "   - `activation='relu'`: Rectified Linear Unit activation to introduce non-linearity.\n",
    "   - `input_shape=(32, 32, 3)`: Shape of each input image (32x32 pixels, 3 color channels).\n",
    "2. **MaxPooling2D layer** with:\n",
    "   - `pool_size=(2, 2)`: Reduces each feature map by a factor of 2, retaining the most salient features.\n",
    "3. A second Conv2D + MaxPooling block, with `filters=64` to learn more complex patterns.\n",
    "4. **Flatten** layer to convert the 3D feature maps to a 1D feature vector.\n",
    "5. **Dense** (fully connected) layers:\n",
    "   - First Dense with `units=64` and `activation='relu'` to learn combinations of features.\n",
    "   - Output Dense with `units=10` (one per class) and `activation='softmax'` to produce a probability distribution over classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304a35e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "# First convolutional block\n",
    "model.add(layers.Conv2D(filters=32,\n",
    "                        kernel_size=(3, 3),\n",
    "                        activation='relu',\n",
    "                        input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Second convolutional block\n",
    "model.add(layers.Conv2D(filters=64,\n",
    "                        kernel_size=(3, 3),\n",
    "                        activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten feature maps to a 1D vector\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Dense layers for classification\n",
    "model.add(layers.Dense(64,\n",
    "                        activation='relu'))  # 64 neurons for learning patterns\n",
    "model.add(layers.Dense(10,\n",
    "                        activation='softmax'))  # 10 outputs for 10 classes\n",
    "\n",
    "# Display model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ee7b1f",
   "metadata": {},
   "source": [
    "## 4. Compiling and Training the Model\n",
    "\n",
    "Before training, we must compile the model by specifying:\n",
    "\n",
    "- `optimizer='adam'`: Adaptive Moment Estimation, a popular gradient-based optimizer.\n",
    "- `loss='sparse_categorical_crossentropy'`: Appropriate for integer labels in multi-class classification.\n",
    "- `metrics=['accuracy']`: Track accuracy during training.\n",
    "\n",
    "We then train the model with:\n",
    "- `epochs=10`: Number of complete passes through the training data.\n",
    "- `batch_size=64`: Number of samples processed before updating the model's weights.\n",
    "- `validation_data=(x_test, y_test)`: Evaluate performance on test set at each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c920fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=64,\n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e65a25",
   "metadata": {},
   "source": [
    "## 5. Evaluating the Model\n",
    "\n",
    "After training, we evaluate the final performance on the test set using `evaluate`, which returns the loss and accuracy. A higher accuracy indicates better classification performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527f3b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f'Test loss: {test_loss:.4f}')\n",
    "print(f'Test accuracy: {test_acc:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b7c3d1",
   "metadata": {},
   "source": [
    "## 6. Making Predictions\n",
    "\n",
    "Finally, let's predict the classes for the first 5 test images:\n",
    "\n",
    "- `model.predict(...)` returns an array of probabilities for each class.\n",
    "- We use `np.argmax(...)` to select the class with the highest probability.\n",
    "- Visualize the image and its predicted label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb041b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test[:5])\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(10, 2))\n",
    "for i in range(5):\n",
    "    axes[i].imshow(x_test[i])\n",
    "    axes[i].set_title('Pred: ' + class_names[predicted_labels[i]])\n",
    "    axes[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3337331",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "- We built a CNN with two convolutional blocks and dense layers for CIFAR-10 classification.\n",
    "- We explained each layer, parameter, and hyperparameter in detail.\n",
    "- Next, you can experiment with more layers, different optimizers, data augmentation, or regularization to improve performance."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
