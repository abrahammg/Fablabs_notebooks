{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d29f159",
   "metadata": {},
   "source": [
    "# Module 3: Simple RNN Practice\n",
    "\n",
    "## Practice: Creating a Simple RNN for Temperature Prediction\n",
    "\n",
    "In this example, we will use a simple Recurrent Neural Network (RNN) to predict daily temperatures based on past records. RNNs are useful for time-series forecasting, such as weather prediction, stock market analysis, and trend detection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8713ea40",
   "metadata": {},
   "source": [
    "## 1. Importing Required Libraries\n",
    "\n",
    "We import NumPy for numerical operations, TensorFlow/Keras to build and train the RNN, Matplotlib for visualization, and Scikit-learn for scaling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff75807",
   "metadata": {},
   "source": [
    "In this cell we import the libraries required for working with RNNs:\n",
    "\n",
    "- **numpy**: For numerical operations with arrays.\n",
    "- **tensorflow** and **keras**: To define and train the RNN.\n",
    "- **matplotlib.pyplot**: For data visualization.\n",
    "- **sklearn.preprocessing.MinMaxScaler**: For scaling the data.\n",
    "\n",
    "A print statement confirms successful imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cc5773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, SimpleRNN, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212c768c",
   "metadata": {},
   "source": [
    "## 2. Load and Visualize Temperature Data\n",
    "\n",
    "We load the daily temperature data from CSV and plot it to observe seasonal patterns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c88f07e",
   "metadata": {},
   "source": [
    "In this cell we load and explore the daily temperature dataset:\n",
    "\n",
    "1. Use **pandas** to read the `daily_temperature.csv` file.\n",
    "2. Extract the `day` and `temperature` columns.\n",
    "3. Plot the temperature over time to visualize the time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c903c7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('./data/daily_temperature.csv')\n",
    "days = df['day'].values\n",
    "temperature = df['temperature'].values\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(days, temperature, label='Temperature')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Temperature (°C)')\n",
    "plt.title('Synthetic Daily Temperature (1 year)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c96e761",
   "metadata": {},
   "source": [
    "## 3. Preparing the Data for the RNN\n",
    "\n",
    "We normalize the temperatures, create sequences of the past 7 days as input, and the next day's temperature as output. Then split into train/test sets (80/20).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c365d66",
   "metadata": {},
   "source": [
    "In this cell we preprocess the data:\n",
    "\n",
    "1. **Scaling**: Transform temperature values to the [0,1] range using `MinMaxScaler`.\n",
    "2. **Sequence creation**: With `sequence_length=7`, create (X, y) pairs where X contains the previous 7 days and y the next day.\n",
    "3. **Train-test split**: Allocate 80% for training and 20% for testing.\n",
    "\n",
    "Print the number of training and testing samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe48e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "temp_scaled = scaler.fit_transform(temperature.reshape(-1,1))\n",
    "\n",
    "# Create sequences\n",
    "sequence_length = 7\n",
    "X, y = [], []\n",
    "for i in range(len(temp_scaled) - sequence_length):\n",
    "    X.append(temp_scaled[i:i+sequence_length])\n",
    "    y.append(temp_scaled[i+sequence_length])\n",
    "X, y = np.array(X), np.array(y)\n",
    "\n",
    "# Split into train/test\n",
    "split = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "print(f\"Training samples: {X_train.shape[0]}, Testing samples: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7596d0d3",
   "metadata": {},
   "source": [
    "## 4. Building and Training the RNN Model\n",
    "\n",
    "We build a Sequential model with one SimpleRNN layer and one Dense output. We compile with Adam optimizer and MSE loss, then train for 50 epochs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1292099",
   "metadata": {},
   "source": [
    "In this cell we define, compile, and train the RNN model:\n",
    "\n",
    "- Start with a Keras **Sequential** model.  \n",
    "- Use an explicit **Input** layer to specify the sequence shape (sequence_length time steps, 1 feature).  \n",
    "- Add a **SimpleRNN** layer with 10 units and **ReLU** activation.  \n",
    "- Finish with a **Dense(1)** layer to predict the next continuous value.  \n",
    "- Compile with the **Adam** optimizer and **MSE** loss, then train for 50 epochs with validation on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612ac439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sequence length as used in preprocessing\n",
    "sequence_length = 7\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(sequence_length, 1)),\n",
    "    SimpleRNN(10, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "history = model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ee9163",
   "metadata": {},
   "source": [
    "## 5. Making Predictions\n",
    "\n",
    "We predict on the test set, inverse-transform the results, and compare predicted vs actual temperatures.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784ba1dc",
   "metadata": {},
   "source": [
    "In this cell we evaluate the model's predictions:\n",
    "\n",
    "1. Call `model.predict` on `X_test` and inverse-transform the scaled values.\n",
    "2. Rescale both predictions and true values to Celsius.\n",
    "3. Plot actual vs. predicted temperature using solid and dashed lines.\n",
    "4. Add labels, title, and legend for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c69b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "predictions = model.predict(X_test)\n",
    "pred_rescaled = scaler.inverse_transform(predictions)\n",
    "y_test_rescaled = scaler.inverse_transform(y_test)\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(y_test_rescaled, label='Actual Temperature')\n",
    "plt.plot(pred_rescaled, label='Predicted Temperature', linestyle='dashed')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Temperature (°C)')\n",
    "plt.title('Temperature Prediction Using RNN')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
