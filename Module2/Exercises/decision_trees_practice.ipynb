{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "467f21e5",
   "metadata": {},
   "source": [
    "# Module 2: Decision Trees Practice\n",
    "\n",
    "## Introduction\n",
    "In this notebook, you'll learn how to implement a Decision Tree classifier using scikit-learn on a multiclass dataset.\n",
    "\n",
    "## Initial Knowledge Check\n",
    "1. What is the main idea behind a decision tree?\n",
    "2. How does tree depth affect underfitting vs. overfitting?\n",
    "3. Explain how splitting criteria (gini vs entropy) differ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392a2186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('./data/decision_trees.csv')\n",
    "X = df[['feature1', 'feature2', 'feature3']]\n",
    "y = df['target']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9dc52e",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis\n",
    "Visualize the relationships between features and the target. We'll start with pairplots.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c9db52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.pairplot(df, hue='target', palette='tab10')\n",
    "plt.suptitle('Pairplot of Decision Tree Demo Data', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75a42c5",
   "metadata": {},
   "source": [
    "## 3. Train a Decision Tree Classifier\n",
    "We'll train a DecisionTreeClassifier with default settings and evaluate on the same data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10b9e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Instantiate and train\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X, y)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = dt.predict(X)\n",
    "acc = accuracy_score(y, y_pred)\n",
    "print(f\"Training Accuracy: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e1b247",
   "metadata": {},
   "source": [
    "## 4. Exercise for the Student\n",
    "**Task:**  \n",
    "1. Vary the `max_depth` parameter from 1 to 10 and record the training and test accuracy.  \n",
    "2. Plot accuracy vs. `max_depth`.  \n",
    "3. Which `max_depth` provides the best test accuracy?  \n",
    "4. **Bonus:** Visualize the tree with `export_text` or `plot_tree`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfca63be",
   "metadata": {},
   "source": [
    "## 5. Solution\n",
    "Below is one possible solution, including splitting into train/test sets and plotting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe519ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "depths = range(1, 11)\n",
    "\n",
    "for d in depths:\n",
    "    clf = DecisionTreeClassifier(max_depth=d, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_acc.append(accuracy_score(y_train, clf.predict(X_train)))\n",
    "    test_acc.append(accuracy_score(y_test, clf.predict(X_test)))\n",
    "\n",
    "# Plot results\n",
    "plt.plot(depths, train_acc, label='Train Accuracy')\n",
    "plt.plot(depths, test_acc,  label='Test Accuracy')\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Decision Tree: Train vs Test Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Best depth\n",
    "best_depth = depths[test_acc.index(max(test_acc))]\n",
    "print(f\"Optimal max_depth based on test set: {best_depth}\")\n",
    "\n",
    "# Bonus: visualize tree\n",
    "plt.figure(figsize=(12,8))\n",
    "plot_tree(clf, feature_names=['feature1','feature2','feature3'], class_names=[str(c) for c in clf.classes_], filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937f1e69",
   "metadata": {},
   "source": [
    "---\n",
    "### Next Steps\n",
    "- Experiment with `criterion='entropy'` and compare results.\n",
    "- Consider how pruning methods (like `min_samples_leaf`) can regularize the tree.\n",
    "- Prepare for Linear Regression by reviewing how continuous targets differ from classification.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
