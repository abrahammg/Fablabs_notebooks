{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d341b2f7",
   "metadata": {},
   "source": [
    "# Module 2: Linear Regression 2 Practice\n",
    "\n",
    "## Introduction\n",
    "In this notebook, you'll learn how to implement a multivariate Linear Regression model using scikit-learn.\n",
    "\n",
    "## Initial Knowledge Check\n",
    "1. Why might multivariate regression be more powerful than univariate?\n",
    "2. What is multicollinearity and why can it be problematic?\n",
    "3. How do you interpret regression coefficients in multivariate context?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c1d626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('./data/linear_regression_2.csv')\n",
    "X = df[['feature1', 'feature2', 'feature3']]\n",
    "y = df['target']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e4c65b",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis\n",
    "Visualize pairwise relationships and correlation matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e1db49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.pairplot(df, vars=['feature1','feature2','feature3'], diag_kind='kde')\n",
    "plt.suptitle('Pairplot of Multivariate Regression Data', y=1.02)\n",
    "plt.show()\n",
    "\n",
    "corr = df.corr()\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1a1f9c",
   "metadata": {},
   "source": [
    "## 3. Train a Multivariate Linear Regression Model\n",
    "We'll train a `LinearRegression` model and evaluate using MSE and R².\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128e5f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Instantiate and train\n",
    "lr = LinearRegression()\n",
    "lr.fit(X, y)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = lr.predict(X)\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "r2 = r2_score(y, y_pred)\n",
    "print(\"Intercept:\", lr.intercept_)\n",
    "print(\"Coefficients:\", lr.coef_)\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "print(f\"R²: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078a4500",
   "metadata": {},
   "source": [
    "## 4. Exercise for the Student\n",
    "**Task:**  \n",
    "1. Split the data into train/test (75/25).  \n",
    "2. Evaluate model performance on both sets.  \n",
    "3. Use statsmodels to fit the same model and display a detailed summary (coefficients, p-values, etc.).  \n",
    "4. **Bonus:** Detect multicollinearity using Variance Inflation Factor (VIF).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf159f10",
   "metadata": {},
   "source": [
    "## 5. Solution\n",
    "Below is one possible solution, including statsmodels and VIF calculation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84edd5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.api import OLS, add_constant\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=24\n",
    ")\n",
    "\n",
    "# Train scikit-learn\n",
    "lr2 = LinearRegression()\n",
    "lr2.fit(X_train, y_train)\n",
    "print('Sklearn Performance:')\n",
    "print('Train R²:', r2_score(y_train, lr2.predict(X_train)))\n",
    "print('Test R²:', r2_score(y_test, lr2.predict(X_test)))\n",
    "\n",
    "# Statsmodels summary\n",
    "X_sm = add_constant(X)\n",
    "model_sm = OLS(y, X_sm).fit()\n",
    "print(model_sm.summary())\n",
    "\n",
    "# Calculate VIF\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data['feature'] = X.columns\n",
    "vif_data['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90413a96",
   "metadata": {},
   "source": [
    "---\n",
    "### Next Steps\n",
    "- Explore regularization methods (Ridge, Lasso) to address multicollinearity.\n",
    "- Review diagnostic plots: residuals, QQ plot, leverage.\n",
    "- Prepare for Logistic Regression by considering binary targets and classification metrics.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
