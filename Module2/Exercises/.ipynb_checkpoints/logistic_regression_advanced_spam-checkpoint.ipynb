{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "599bbcdd",
   "metadata": {},
   "source": [
    "# Spam Detection with Logistic Regression\n",
    "\n",
    "In this notebook, we'll train a Logistic Regression model to classify emails as \"spam\" or \"ham\" based on their content.\n",
    "\n",
    "We will:\n",
    "1. Load and preprocess the dataset.\n",
    "2. Convert the text into numerical features using `TfidfVectorizer`.\n",
    "3. Split the data into training and test sets.\n",
    "4. Train a Logistic Regression model.\n",
    "5. Evaluate the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fc8fa2",
   "metadata": {},
   "source": [
    "## Step 1: Load and explore the dataset\n",
    "\n",
    "We first load the CSV file containing 5000 emails labeled as either \"spam\" or \"ham\". Let's inspect the first few rows to understand the structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b97f276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"spam_data.csv\")  # Cambiar o nome ao CSV final\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c1f553",
   "metadata": {},
   "source": [
    "## Step 2: Preprocess labels\n",
    "\n",
    "We convert the textual labels into numerical values: 0 for ham, 1 for spam. We also check for missing values that could affect training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd8430d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map 'ham' to 0 and 'spam' to 1\n",
    "df[\"label_num\"] = df[\"label\"].map({\"ham\": 0, \"spam\": 1})\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3148a633",
   "metadata": {},
   "source": [
    "## Step 3: Split the dataset\n",
    "\n",
    "We separate the features (email text) and the labels, and split the data into a training set (80%) and a test set (20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3ec5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[\"text\"]\n",
    "y = df[\"label_num\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d69b8d",
   "metadata": {},
   "source": [
    "## Step 4: Convert text to numeric features with TF-IDF\n",
    "\n",
    "Text data needs to be transformed into numerical vectors. We use TF-IDF to give weight to relevant words while ignoring common ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e9ccb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_df=0.9)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7fd924",
   "metadata": {},
   "source": [
    "## Step 5: Train the Logistic Regression model\n",
    "\n",
    "We now train the Logistic Regression model using the TF-IDF transformed training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56006cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c039fcbe",
   "metadata": {},
   "source": [
    "## Step 6: Evaluate the model\n",
    "\n",
    "Finally, we evaluate how well our model performs. We check accuracy, confusion matrix (to see false positives/negatives), and precision/recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bb9ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b41d956",
   "metadata": {},
   "source": [
    "### Interactive Test\n",
    "\n",
    "Try your own email sample and see the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8ddb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [\"Win a FREE trip to Bahamas! Click here now!\"]\n",
    "sample_tfidf = vectorizer.transform(sample)\n",
    "print(\"Prediction:\", \"spam\" if model.predict(sample_tfidf)[0] == 1 else \"ham\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8d2df4",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- Processed text for classification.\n",
    "- Used TF-IDF for feature extraction.\n",
    "- Trained a Logistic Regression model for spam detection.\n",
    "- Evaluated performance with standard metrics.\n",
    "\n",
    "Next step: Experiment with hyperparameters or try different algorithms like Naive Bayes or KNN."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
